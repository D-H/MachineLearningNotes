{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the reasons we use convolutional neural networks is because our inputs get very large. Lets say we have a 1000 by 1000 image with 3 color channels. Now that would be inputs of 3 million and in our first layer we have 1000 weights. Well, so then our weight matrix is going to be of size 3 billion. This is very large and it will be hard to find enough data to train a weight matrix that is this large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general idea, is that if your data has some structure. And if your neural network doesn't have to learn that structure from scratch it is going to perform better. \n",
    "\n",
    "Translation-Invariance: When it doesn't really matter when your the object you are trying to recognize occurs in the object. Because you are still trying to find that object specifically. \n",
    "\n",
    "Statistical Invariance: Things that don't change across time or space.\n",
    "\n",
    "The way we acheive this in __neural networks__ is with weight sharing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks are networks that share their parameters across space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding and recurent neural networks\n",
    "\n",
    "__Patch__: Is the size of the kernel you put over the image when creating your neural network\n",
    "\n",
    "__Depth__: Is the amount of depth your layer currently has. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Feature Map__: Each pancake in your stack is called a feature map\n",
    "\n",
    "__Stride__: Number of pixels you are moving each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of your stride and also how you implement you padding (Same or Valid) will change the size of your output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to do to improve your convolutional neural net.\n",
    "- Pooling\n",
    "- 1x1 Convolutions\n",
    "- Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional networks are very good because they match on pieces of an image instead of the whole image. \n",
    "\n",
    "The math behind the matching is called __filtering__\n",
    "1. Line up the feature and image patch\n",
    "2. Multiply each pixel by the corresponding feature pixel\n",
    "3. Add them up\n",
    "4. Divide by the total number of pixels in the feature\n",
    "\n",
    "Let's say you are doing this with a black and white picture and you assign white values to be 1 and black values to be -1. You will get the best results when the pixels line up perfectly. \n",
    "\n",
    "__Convolution:__ Trying every possible match, the symbol for convolution is the circle with the X in the middle. \n",
    "\n",
    "__Convolution Layer:__ One image becomes a stack of filtered images. This is what convolution with different filters can do for you.\n",
    "\n",
    "__Pooling:__ Shrinking the image stack. I believe that you do this on all of the convolution layers.\n",
    "\n",
    "1. Pick a window size (usually 2 or 3)\n",
    "2. Pick a stride (usually 2)\n",
    "3. Walk your window across your filtered images. \n",
    "4. From each window, the maximum value. \n",
    "\n",
    "Pooling won't care exactly where in the window the maximum values occured so it will start removing some of the dependence on position.\n",
    "\n",
    "If your data is just as usefull after swapping any of your columns then using a convolutional neural networks is probably not right for your application.\n",
    "\n",
    "In a neural network not every neuron in each layer is connected to each neuron in the next layer because this would be very computationally expensive. \n",
    "\n",
    "You just run these steps over and over again.\n",
    "1. Convolution\n",
    "2. Relu\n",
    "3. Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different type of choices you can make with your convulutions when reaching the edges. If you decide not to take your kernel off the image that is called __valid__ padding.\n",
    "\n",
    "If you decide to go off the edge and pad with 0's that is called __same__ padding. With the same padding you don't take the filter completely off the edge at most the farthest you take it off the edge is so that the center of the filter is at the corner of the image (input)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
