{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow\n",
    "\n",
    "TensorFlow supports both CPU's and GPU's computing devices\n",
    "\n",
    "TensorFlow uses a __dataflow graph__ to represent your computation in terms of the dependencies between individual operations. This leads to a low-level programming model in which you first define the dataflow graph, then create a TensorFlow __session__ to run parts of the graph across a set of local and remote devices.\n",
    "\n",
    "A default __Graph__ is always registered so you can always just call something like this...\n",
    "\n",
    "There are going to be code examples in this notebook so I will import a whole bunch of __libraries.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    # Define operations and tensors in `g`\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tensor__ is a core concept for TensorFlow. TensorFlow programs use a tensor data structure to represent all data -- only tensors are passed between operations in the computation graph. You can think of a TensorFlow tensor as an n-dimensional array or list. \n",
    "\n",
    "For example, a scaler is a tensor, a vector is a tensor and a matrix is a tensor. A tensor has a rank, shape and static type. The __rank__ of a matrix is defined as (a) the maximum number of linearly independent column vectors in the matrix (b) the maximum number of linearly independent row vectors in the matrix. Both definitions are equivenlent. \n",
    "\n",
    "for an (r,c) matrix\n",
    "    - If r is less than c, then the maximum rank of the matrix is r.\n",
    "    - If r is greater than c, then the maximum rank of a matrix is c. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Variables__ are in-memory buffers containing tensors, when you train a model with TensorFlow, variables can be used to hold and update parameters. Variables must be explicitly initialized and can be saved to disk during and after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'my_variable1:0' shape=(1, 2, 3) dtype=float32_ref>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable = tf.get_variable(\"my_variable1\", [1, 2, 3])\n",
    "variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The difference between a Tensor and Variable__ is a variable is essentially just a wrapper around a Tensor that will maintain state across multiple calls to run().\n",
    "\n",
    "__Feed__ temporarily replaces the output of an operation with a tensor value. You supply feed data as an argument to the run() call.  \n",
    "\n",
    "__tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)__ -> Ouputs random variables from a truncated normal distribution.\n",
    "\n",
    "__Cross entropy__ is often our target function. Suppose we have some fixed model, which predicts n classes {1, 2, ... n} and their hypothetical occurence probabilities y1, y2, ..., yn. Now suppose in reality you now observe (in reality) k1 instances of class 1, k2 instances of class 2, kn instances of class n, etc. Looking at this we see that if the you have a really low hypothetical value but it shows up a lot then you will end up with a high cross entropy. It seems like it punishes you more for the classes with lower probabilities.\n",
    "\n",
    "With cross entropy we can measure how our neural net is doing my measuring the prediction of the class vs the one hot enoded vector. \n",
    "\n",
    "If our one hot encoded classes look like this\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "           0 \\\\\n",
    "           0 \\\\\n",
    "           1 \\\\\n",
    "\\end{bmatrix}$ \n",
    "\n",
    "and our predictions look like this\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "           0.3 \\\\\n",
    "           0.1 \\\\\n",
    "           0.6 \\\\\n",
    "\\end{bmatrix}$ \n",
    "\n",
    "Then our cross entropy calculation would be equal to $-(1)log(0.6)$ so as our prediction gets better the cross entropy will get smaller. \n",
    "\n",
    "A __Placeholder__ is simply a variable that we will assign data to at a later date. It allows us to create our operations and build our computation graph, without needing the data. A strange thing about placeholder shapes is that if something has the shape [] it will take a single scalar value directly. Placeholder with [None] shape takes a 1-dimensional array and a placeholder set to simply None can take any shape while computation takes place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__tf.global_variables_initializer().run():__ Returns an Op that will initialize the global variables in the graph. This needs to be called if it is not included then you get a pretty non-intuitive error.\n",
    "\n",
    "__feed_dict__: You use the feed_dict to give values to all the placeholder variables. The arguments to a placeholder are \n",
    "\n",
    "- dtype: The type of elements the tensor to be fed\n",
    "- shape: The shape of the tensor to be fed\n",
    "- name: The name of the operation\n",
    "\n",
    "__tf.matmul__: Typically used like tf.matmul(a, b) and the equal to doing a * b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you are trying to set where the tensorflow event files are set to then you can use the following code snippet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Example -> writer = tf.summary.FileWriter(\"C:\\\\Users\\\\David\\\\Development\\\\MachineLearning\\\\TensorFlowEventFiles\", session.graph)\n",
    "    writer = tf.summary.FileWriter(\"PathToDirectory\", sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TensorBoard from TensorFlow event files.\n",
    "\n",
    "1) Open up the Anaconda promt\n",
    "2) You can open up the NeuralNetwork graph by using this command (tensorboard --logdir=C:\\\\Users\\\\David\\\\Development\\\\MachineLearning\\\\TensorFlowEventFiles)\n",
    "\n",
    "You can view the TensorBoard at this URL -> http://DESKTOP-2RTJM2C:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a very simple session for TensorBoard to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mul:0\", shape=(), dtype=float32)\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2.0)\n",
    "b = tf.constant(3.0)\n",
    "c = b*a\n",
    "print(c)\n",
    "with tf.Session() as session:\n",
    "  #Used to create tensor flow event files that can be used with tensor board for debugging purposes\n",
    "  writer = tf.summary.FileWriter(\"C:\\\\Users\\\\David\\\\Development\\\\MachineLearning\\\\TensorFlowEventFiles\", session.graph)\n",
    "  print(session.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a fairly simple graph that involves a __placeholder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = a*2\n",
    "with tf.Session() as session:\n",
    "    result = session.run(b, feed_dict={a:3})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You close a TensorFlow session using the session.close() function. You will only need to use this if you are not using the \"with tf.Session() as session:\" systax\n",
    "\n",
    "What is the TensorFlow default graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.feature_column.categorical_column_with_vocabulary_list?\n",
    "tf.feature_column.categorical_column_with_hash_bucket?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__accuracy__ with measure how often predictions are equal to the labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tensorflow you can measure the __L2 loss__ of a tensor t using the __tf.nn.l2_loss(t)__ function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated Gaussian\n",
    "\n",
    "This is same from sampaling from a truncated gaussian but any values that are drawn that are over 2 standard deviations will be re-drawn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2d\n",
    "\n",
    "Computes a 2-D convolution given a 4-D input and filter tensors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
