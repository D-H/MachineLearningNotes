{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do Deep Learning You Need\n",
    "\n",
    "1. Lots of Data\n",
    "2. Complex Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief History of Neural Networks\n",
    "\n",
    "1. Alot of the work happend in the 80s\n",
    "2. In the 2000's computers go cheaper\n",
    "3. Today neural networks are everywhere thanks to lots of Data and cheap GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of __Classification__ is taking in a input and giving it a label. Classification is the central building block of machine learning. \n",
    "\n",
    "You are usually given a training set to train your model.\n",
    "\n",
    "A logistic classfier is also know as a linear classifer. It takes the form, WX + b = y\n",
    "\n",
    "- W is the weights\n",
    "- X is the inputs \n",
    "- b is the bias term\n",
    "- y is the scores\n",
    "\n",
    "We will train the weights and bias using machine learning. \n",
    "\n",
    "We can then turn those scores into probabilites using the softmax. Softmax can take any kind of score and turn them into probailities. \n",
    "\n",
    "Scores in the context of logistic regression, are often called __logits__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are training our model we have 3 kinds of data\n",
    "\n",
    "- Training\n",
    "- Validation\n",
    "- Testing\n",
    "\n",
    "We do this because we want to ensure our classifier has not just memorized the training set.\n",
    "\n",
    "So what is we do is a process of trial and error where we create models and test them against the validation dataset. Finally when we are fully satisfied with our results can we actually validate against the Test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised vs Unsupervised Learning\n",
    "\n",
    "__Supervised learning__ is when we have training data with labeled categories. The training data consist of a set of training examples. In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called thesupervisory signal).\n",
    "\n",
    "__Unsupervised__ learning is that of trying to find hidden structure in unlabeled data. Since the examples given to the learner are unlabeled, there is no error or reward signal to evaluate a potential solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule Of '30'\n",
    "\n",
    "Under the null hypothesis that New Model is the same as Old Model except for noise,  arbitrarily many test samples can flip, given enough noise. However if you change over 30 examples in your validation set then you can assume that it is more than noise. \n",
    "\n",
    "This means that usually people hold off on 30, 000 examples for the validation set, which means that any change > 0.1% means a change in accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "Stochastic Gradient Descent is similar to Gradient Descent, the only real difference is we don't use all our data every time we compute the gradient. Because we do not do this sometimes our gradient desent will not be hyper accurate. But because it will be so much cheaper we can run it many more times. It makes gradient descent much more scalable. \n",
    "\n",
    "We often want to create a decaying learning rate as we go along in SGD.\n",
    "\n",
    "You often want a slower learning rate, it's often true that slower learning rates will give you a better model. \n",
    "\n",
    "If you use an algorithm like ADAGRAD, which is a modification of stochastic gradient descent it will automatically handle the modification of the learning rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Epoch__ is a term that is often used in the context of machine learning. An epoch is one complete presentation of the data set to be learned to a learning machine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
